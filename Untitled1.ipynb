{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNvStWRb4kVHOfmfu3Bf4py",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JackMa-coder/QtIPEdit/blob/master/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPhBx1Uo6PAC",
        "outputId": "5748338d-19d2-471b-c548-111a9fe4a418"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "__all__ = ['MobileNetV3', 'mobilenetv3']\n",
        "\n",
        "\n",
        "def conv_bn(inp, oup, stride, conv_layer=nn.Conv2d, norm_layer=nn.BatchNorm2d, nlin_layer=nn.ReLU):\n",
        "    return nn.Sequential(\n",
        "        conv_layer(inp, oup, 3, stride, 1, bias=False),\n",
        "        norm_layer(oup),\n",
        "        nlin_layer(inplace=True)\n",
        "    )\n",
        "\n",
        "\n",
        "def conv_1x1_bn(inp, oup, conv_layer=nn.Conv2d, norm_layer=nn.BatchNorm2d, nlin_layer=nn.ReLU):\n",
        "    return nn.Sequential(\n",
        "        conv_layer(inp, oup, 1, 1, 0, bias=False),\n",
        "        norm_layer(oup),\n",
        "        nlin_layer(inplace=True)\n",
        "    )\n",
        "\n",
        "\n",
        "class Hswish(nn.Module):\n",
        "    def __init__(self, inplace=True):\n",
        "        super(Hswish, self).__init__()\n",
        "        self.inplace = inplace\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * F.relu6(x + 3., inplace=self.inplace) / 6.\n",
        "\n",
        "\n",
        "class Hsigmoid(nn.Module):\n",
        "    def __init__(self, inplace=True):\n",
        "        super(Hsigmoid, self).__init__()\n",
        "        self.inplace = inplace\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.relu6(x + 3., inplace=self.inplace) / 6.\n",
        "\n",
        "\n",
        "class SEModule(nn.Module):\n",
        "    def __init__(self, channel, reduction=4):\n",
        "        super(SEModule, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channel, channel // reduction, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channel // reduction, channel, bias=False),\n",
        "            Hsigmoid()\n",
        "            # nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        return x * y.expand_as(x)\n",
        "\n",
        "\n",
        "class Identity(nn.Module):\n",
        "    def __init__(self, channel):\n",
        "        super(Identity, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x\n",
        "\n",
        "\n",
        "def make_divisible(x, divisible_by=8):\n",
        "    import numpy as np\n",
        "    return int(np.ceil(x * 1. / divisible_by) * divisible_by)\n",
        "\n",
        "\n",
        "class MobileBottleneck(nn.Module):\n",
        "    def __init__(self, inp, oup, kernel, stride, exp, se=False, nl='RE'):\n",
        "        super(MobileBottleneck, self).__init__()\n",
        "        assert stride in [1, 2]\n",
        "        assert kernel in [3, 5]\n",
        "        padding = (kernel - 1) // 2\n",
        "        self.use_res_connect = stride == 1 and inp == oup\n",
        "\n",
        "        conv_layer = nn.Conv2d\n",
        "        norm_layer = nn.BatchNorm2d\n",
        "        if nl == 'RE':\n",
        "            nlin_layer = nn.ReLU # or ReLU6\n",
        "        elif nl == 'HS':\n",
        "            nlin_layer = Hswish\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "        if se:\n",
        "            SELayer = SEModule\n",
        "        else:\n",
        "            SELayer = Identity\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            # pw\n",
        "            conv_layer(inp, exp, 1, 1, 0, bias=False),\n",
        "            norm_layer(exp),\n",
        "            nlin_layer(inplace=True),\n",
        "            # dw\n",
        "            conv_layer(exp, exp, kernel, stride, padding, groups=exp, bias=False),\n",
        "            norm_layer(exp),\n",
        "            nlin_layer(inplace=True),\n",
        "            SELayer(exp),\n",
        "            \n",
        "            # pw-linear\n",
        "            conv_layer(exp, oup, 1, 1, 0, bias=False),\n",
        "            norm_layer(oup),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.use_res_connect:\n",
        "            return x + self.conv(x)\n",
        "        else:\n",
        "            return self.conv(x)\n",
        "\n",
        "\n",
        "class MobileNetV3(nn.Module):\n",
        "    def __init__(self, n_class=1000, input_size=224, dropout=0.8, mode='small', width_mult=1.0):\n",
        "        super(MobileNetV3, self).__init__()\n",
        "        input_channel = 16\n",
        "        last_channel = 1280\n",
        "        if mode == 'large':\n",
        "            # refer to Table 1 in paper\n",
        "            mobile_setting = [\n",
        "                # k, exp, c,  se,     nl,  s,\n",
        "                [3, 16,  16,  False, 'RE', 1],\n",
        "                [3, 64,  24,  False, 'RE', 2],\n",
        "                [3, 72,  24,  False, 'RE', 1],\n",
        "                [5, 72,  40,  True,  'RE', 2],\n",
        "                [5, 120, 40,  True,  'RE', 1],\n",
        "                [5, 120, 40,  True,  'RE', 1],\n",
        "                [3, 240, 80,  False, 'HS', 2],\n",
        "                [3, 200, 80,  False, 'HS', 1],\n",
        "                [3, 184, 80,  False, 'HS', 1],\n",
        "                [3, 184, 80,  False, 'HS', 1],\n",
        "                [3, 480, 112, True,  'HS', 1],\n",
        "                [3, 672, 112, True,  'HS', 1],\n",
        "                [5, 672, 160, True,  'HS', 2],\n",
        "                [5, 960, 160, True,  'HS', 1],\n",
        "                [5, 960, 160, True,  'HS', 1],\n",
        "            ]\n",
        "        elif mode == 'small':\n",
        "            # refer to Table 2 in paper\n",
        "            mobile_setting = [\n",
        "                # k, exp, c,  se,     nl,  s,\n",
        "                [3, 16,  16,  True,  'RE', 2],\n",
        "                [3, 72,  24,  False, 'RE', 2],\n",
        "                [3, 88,  24,  False, 'RE', 1],\n",
        "                [5, 96,  40,  True,  'HS', 2],\n",
        "                [5, 240, 40,  True,  'HS', 1],\n",
        "                [5, 240, 40,  True,  'HS', 1],\n",
        "                [5, 120, 48,  True,  'HS', 1],\n",
        "                [5, 144, 48,  True,  'HS', 1],\n",
        "                [5, 288, 96,  True,  'HS', 2],\n",
        "                [5, 576, 96,  True,  'HS', 1],\n",
        "                [5, 576, 96,  True,  'HS', 1],\n",
        "            ]\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "        # building first layer\n",
        "        assert input_size % 32 == 0\n",
        "        last_channel = make_divisible(last_channel * width_mult) if width_mult > 1.0 else last_channel\n",
        "        self.features = [conv_bn(3, input_channel, 2, nlin_layer=Hswish)]\n",
        "        self.classifier = []\n",
        "\n",
        "        # building mobile blocks\n",
        "        for k, exp, c, se, nl, s in mobile_setting:\n",
        "            output_channel = make_divisible(c * width_mult)\n",
        "            exp_channel = make_divisible(exp * width_mult)\n",
        "            self.features.append(MobileBottleneck(input_channel, output_channel, k, s, exp_channel, se, nl))\n",
        "            input_channel = output_channel\n",
        "\n",
        "        # building last several layers\n",
        "        if mode == 'large':\n",
        "            last_conv = make_divisible(960 * width_mult)\n",
        "            self.features.append(conv_1x1_bn(input_channel, last_conv, nlin_layer=Hswish))\n",
        "            self.features.append(nn.AdaptiveAvgPool2d(1))\n",
        "            self.features.append(nn.Conv2d(last_conv, last_channel, 1, 1, 0))\n",
        "            self.features.append(Hswish(inplace=True))\n",
        "        elif mode == 'small':\n",
        "            last_conv = make_divisible(576 * width_mult)\n",
        "            self.features.append(conv_1x1_bn(input_channel, last_conv, nlin_layer=Hswish))\n",
        "            # self.features.append(SEModule(last_conv))  # refer to paper Table2, but I think this is a mistake\n",
        "            self.features.append(nn.AdaptiveAvgPool2d(1))\n",
        "            self.features.append(nn.Conv2d(last_conv, last_channel, 1, 1, 0))\n",
        "            self.features.append(Hswish(inplace=True))\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "        # make it nn.Sequential\n",
        "        self.features = nn.Sequential(*self.features)\n",
        "\n",
        "        # building classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=dropout),    # refer to paper section 6#TF实现采用conv2d,不知是否取舍\n",
        "            # nn.Linear(last_channel, n_class),\n",
        "            nn.Conv2d(last_channel, n_class, 1, 1),#TF实现采用conv2d\n",
        "        )\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        # x = x.mean(3).mean(2)#TF实现采用conv2d\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        # weight initialization\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.ones_(m.weight)\n",
        "                nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "\n",
        "\n",
        "def mobilenetv3(pretrained=False, **kwargs):\n",
        "    model = MobileNetV3(**kwargs)\n",
        "    if pretrained:\n",
        "        state_dict = torch.load('mobilenetv3_small_67.4.pth.tar')\n",
        "        model.load_state_dict(state_dict, strict=True)\n",
        "        # raise NotImplementedError\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    net = mobilenetv3()\n",
        "    print('mobilenetv3:\\n', net)\n",
        "    print('Total params: %.2fM' % (sum(p.numel() for p in net.parameters())/1000000.0))\n",
        "    input_size=(1, 3, 224, 224)\n",
        "    # pip install --upgrade git+https://github.com/kuan-wang/pytorch-OpCounter.git\n",
        "\n",
        "    x = torch.randn(input_size)\n",
        "    out = net(x)\n",
        "    \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mobilenetv3:\n",
            " MobileNetV3(\n",
            "  (features): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): Hswish()\n",
            "    )\n",
            "    (1): MobileBottleneck(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
            "        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(inplace=True)\n",
            "        (6): SEModule(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=16, out_features=4, bias=False)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=4, out_features=16, bias=False)\n",
            "            (3): Hsigmoid()\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (2): MobileBottleneck(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
            "        (4): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(inplace=True)\n",
            "        (6): Identity()\n",
            "        (7): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (3): MobileBottleneck(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
            "        (4): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(inplace=True)\n",
            "        (6): Identity()\n",
            "        (7): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (4): MobileBottleneck(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): Hswish()\n",
            "        (3): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
            "        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): Hswish()\n",
            "        (6): SEModule(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=96, out_features=24, bias=False)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=24, out_features=96, bias=False)\n",
            "            (3): Hsigmoid()\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (5): MobileBottleneck(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): Hswish()\n",
            "        (3): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
            "        (4): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): Hswish()\n",
            "        (6): SEModule(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=240, out_features=60, bias=False)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=60, out_features=240, bias=False)\n",
            "            (3): Hsigmoid()\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (6): MobileBottleneck(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): Hswish()\n",
            "        (3): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
            "        (4): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): Hswish()\n",
            "        (6): SEModule(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=240, out_features=60, bias=False)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=60, out_features=240, bias=False)\n",
            "            (3): Hsigmoid()\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (7): MobileBottleneck(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): Hswish()\n",
            "        (3): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
            "        (4): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): Hswish()\n",
            "        (6): SEModule(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=120, out_features=30, bias=False)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=30, out_features=120, bias=False)\n",
            "            (3): Hsigmoid()\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (8): MobileBottleneck(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): Hswish()\n",
            "        (3): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
            "        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): Hswish()\n",
            "        (6): SEModule(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=144, out_features=36, bias=False)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=36, out_features=144, bias=False)\n",
            "            (3): Hsigmoid()\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (9): MobileBottleneck(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): Hswish()\n",
            "        (3): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
            "        (4): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): Hswish()\n",
            "        (6): SEModule(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=288, out_features=72, bias=False)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=72, out_features=288, bias=False)\n",
            "            (3): Hsigmoid()\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (10): MobileBottleneck(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): Hswish()\n",
            "        (3): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
            "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): Hswish()\n",
            "        (6): SEModule(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=576, out_features=144, bias=False)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=144, out_features=576, bias=False)\n",
            "            (3): Hsigmoid()\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (11): MobileBottleneck(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): Hswish()\n",
            "        (3): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
            "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): Hswish()\n",
            "        (6): SEModule(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=576, out_features=144, bias=False)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=144, out_features=576, bias=False)\n",
            "            (3): Hsigmoid()\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (12): Sequential(\n",
            "      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): Hswish()\n",
            "    )\n",
            "    (13): AdaptiveAvgPool2d(output_size=1)\n",
            "    (14): Conv2d(576, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (15): Hswish()\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.8, inplace=False)\n",
            "    (1): Conv2d(1280, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            ")\n",
            "Total params: 2.94M\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}